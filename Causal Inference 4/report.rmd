---
title: 'Causal Inference #4'
author: 'Javier Esteban Aragoneses, Mauricio Marcos Fajgenbaun, Danyu Zhang, Daniel Alonso'
date: 'March 20, 2021'
output: 'pdf_document'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
collapse = TRUE,
comment = '#>',
fig.path = './figures/'
)
knitr::knit_engines$set(julia = JuliaCall::eng_juliacall)
options(JULIA_HOME = '/home/dreth/julia/bin')
```

# Introduction

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# importing libraries
pkgs <- c("glmnet", "rpart", "rpart.plot", "randomForest", "devtools", "tidyverse", "knitr", "caret", "xgboost", "causalTree","grf", "fastDummies", "stringr", 'caret')
invisible(lapply(pkgs, library, character.only = TRUE))
```

# Model

```{r, echo=TRUE, warning=FALSE, message=FALSE}
# importing data
df <- read.csv('./data/gendata.csv', sep=';')
df <- df[2:length(names(df))]
df[2:length(names(df))] <- lapply(df[2:length(names(df))], FUN=as.factor)
preds <- names(df[names(df) != 'conc'])
df <- dummy_cols(df)
df <- df[,!(names(df) %in% preds)]
```

```{r, echo=TRUE, warning=FALSE, message=FALSE}
# Random forest to find most important variable
form <- as.formula(str_interp("conc~${paste(names(df)[names(df)!='conc'], collapse='+')}"))
rf <- randomForest(form,data=df ,importance=TRUE ,mtry=3 ,ntree=1000)
varImpPlot(rf, main="Variable importance")
```


# Causal forest

```{r, echo=TRUE, warning=FALSE, message=FALSE}
# traintest
set.seed(12)
spl <- caret::createDataPartition(df$conc, p = 0.8, list = FALSE)
Train <- df[spl,]
Test <- df[-spl,]

# train
X_train = Train[names(Train) != 'conc' & names(Train) != 'snp1_1']
Y_train = Train[,"conc"]
W_train = Train[,"snp1_1"]

# test
X_test = Test[names(Test) != 'conc' & names(Test) != 'snp1_1']
Y_test = Test[,"conc"]
W_test = Test[,"snp1_1"]

# causal forests
cf = causal_forest(X_train,Y_train,W_train,num.trees =10000)

# Predict with confidence intervals
pred <- predict(cf, X_test, estimate.variance = TRUE)
sigma.hat <- sqrt(pred$variance.estimate)
plot(X_test[,1], pred$predictions, ylim=range(pred$predictions + qnorm(0.975) * sigma.hat, pred$predictions - qnorm(0.975) * sigma.hat), xlam = "x", ylab = "tau", type="l")
lines(X_test[, 1], tau.hat$predictions + 1.96 * sigma.hat, col = 1, lty = 2)
lines(X_test[, 1], tau.hat$predictions - 1.96 * sigma.hat, col = 1, lty = 2)
lines(X_test[, 1], pmax(0, X_test[, 1]), col = 2, lty = 1)

```
```{r, echo=TRUE, warning=FALSE, message=FALSE}
n <- 500
p <- 10
X <- matrix(rnorm(n * p), n, p)
W <- rbinom(n, 1, 0.5)
Y <- pmax(X[, 1], 0) * W + X[, 2] + pmin(X[, 3], 0) + rnorm(n)
```